{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3bfc6c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for LDA on training subset: 2.5%\n",
      "Error rate for LDA on testing subset: 0.0%\n",
      "\n",
      "Error rate for QDA on training subset: 1.6666666666666714%\n",
      "Error rate for QDA on testing subset: 0.0%\n",
      "\n",
      "LDA error rates (%) when respective attribute is dropped:  {'sepal length': '0.0', 'sepal width': '0.0', 'petal length': '0.0', 'petal width ': '3.3333333333333286'}\n",
      "QDA error rates (%) when respective attribute is dropped:  {'sepal length': '0.0', 'sepal width': '0.0', 'petal length': '0.0', 'petal width ': '3.3333333333333286'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "data = pd.io.parsers.read_csv(\n",
    "    filepath_or_buffer='http://www.cse.scu.edu/~yfang/coen140/iris.data',\n",
    "    header=None,\n",
    "    sep=',',\n",
    "    )\n",
    "\n",
    "\n",
    "# def test_dataset(data):\n",
    "#     if len(data) != 150:\n",
    "#         print(len(data))\n",
    "#         return False\n",
    "#     for row in data:\n",
    "#         #if len(row) != 5:\n",
    "#             #return False\n",
    "#         #for column in row[:-1]:\n",
    "#             #if type(column) != np.float64:\n",
    "#                 #return False\n",
    "#         if type(row[-1]) != str:\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "#test_dataset(data)\n",
    "\n",
    "\n",
    "training = data[0:40].append(data[50:90]).append(data[100:140])\n",
    "testing  = data[40:50].append(data[90:100]).append(data[140:150])\n",
    "\n",
    "X_training = training.iloc[:,:-1]\n",
    "X_testing = testing.iloc[:,:-1]\n",
    "y_training = training.iloc[:,-1]\n",
    "y_testing = testing.iloc[:,-1]\n",
    "\n",
    "LDA = lda(solver=\"svd\",store_covariance=True)\n",
    "\n",
    "y_pred_lda_training = LDA.fit(X_training, y_training).predict(X_training)\n",
    "y_pred_lda_testing = LDA.fit(X_training, y_training).predict(X_testing)\n",
    "\n",
    "\n",
    "def accuracy(analysis,test,total):\n",
    "    correct =0\n",
    "    for i in range(total):\n",
    "        if analysis[i] == test.iloc[i]:\n",
    "            correct +=1\n",
    "    accuracy = (correct/total) * 100\n",
    "    error = 100 - accuracy\n",
    "    return str(error)\n",
    "\n",
    "\n",
    "print(\"Error rate for LDA on training subset: \" + accuracy(y_pred_lda_training, y_training, len(y_training)) + \"%\")\n",
    "print(\"Error rate for LDA on testing subset: \" + accuracy(y_pred_lda_testing, y_testing, len(y_testing)) + \"%\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as qda\n",
    "\n",
    "QDA = qda(store_covariance=True)\n",
    "y_pred_qda_training = QDA.fit(X_training, y_training).predict(X_training)\n",
    "y_pred_qda_testing = QDA.fit(X_training, y_training).predict(X_testing)\n",
    "\n",
    "print(\"\\nError rate for QDA on training subset: \" + accuracy(y_pred_qda_training, y_training, len(y_training)) + \"%\")\n",
    "print(\"Error rate for QDA on testing subset: \" + accuracy(y_pred_qda_testing, y_testing, len(y_testing)) + \"%\")\n",
    "\n",
    "\n",
    "LDA_accuracy = {}\n",
    "QDA_accuracy = {}\n",
    "\n",
    "featureDict = {i:label for i,label in zip(range(4),\n",
    "                  ('sepal length',\n",
    "                  'sepal width',\n",
    "                  'petal length',\n",
    "                  'petal width ', ))}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for feature in range(0,4):\n",
    "        \n",
    "    # drop the desired feature    \n",
    "    X_training_drop = X_training.drop(feature,axis=1)\n",
    "    X_testing_drop = X_testing.drop(feature,axis=1)\n",
    "    \n",
    "    # train with LDA and QDA now that we have new tables with one dropped attribute\n",
    "    y_pred_lda_test_drop = LDA.fit(X_training_drop, y_training).predict(X_testing_drop)\n",
    "    y_pred_qda_test_drop = QDA.fit(X_training_drop, y_training).predict(X_testing_drop)\n",
    "    \n",
    "    # important to remember that dictionary values refer to error percentage\n",
    "    LDA_accuracy[feature] = accuracy(y_pred_lda_test_drop, y_testing, len(y_testing))\n",
    "    QDA_accuracy[feature] = accuracy(y_pred_qda_test_drop, y_testing, len(y_testing))\n",
    "    \n",
    "    # change the dictionary keys to be the flower attributes\n",
    "    LDA_accuracy[featureDict[feature]] = LDA_accuracy.pop(feature)\n",
    "    QDA_accuracy[featureDict[feature]] = QDA_accuracy.pop(feature)\n",
    "    \n",
    "print('\\nLDA error rates (%) when respective attribute is dropped: ', LDA_accuracy)\n",
    "print('QDA error rates (%) when respective attribute is dropped: ', QDA_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aeea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on this, petal width is the most important, and the rest dont matter as long as the rest are there"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
